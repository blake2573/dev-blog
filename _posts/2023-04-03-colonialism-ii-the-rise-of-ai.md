---
title: "Colonialism II: The Rise of AI"
date: 2023-04-03
---

As someone who has been writing software since I was 10 years old, there is no question that I am fascinated by the rise of AI. We’ve all seen the sci-fi movies from the 80’s where robots are taking over the world, or fighting crime, or the myriad of other portrayals from pop culture over the years. The idea that it’s here today is something I never thought I would see until I was much older. But as someone with an interest in language, the additional fascination with how these large language models (LLMs) process, understand, and generate cohesive text is something else entirely. The fact that an ability previously seen as exclusively human could be replicated to a certifiable degree with technology is an astounding feat of engineering.

However, it also raises concerns about the negative impacts that these same AI models could have on the diversity and richness of human language.

LLMs are trained on large sets of common datasets in order to perform the “magic” that we are becoming more and more accustomed to experiencing in our everyday lives. Datasets such as [C4](https://www.tensorflow.org/datasets/catalog/c4) (often referred to as Common Crawl), [the Pile](https://pile.eleuther.ai/), [The BigScience Roots Corpus](https://arxiv.org/abs/2303.03915), and [OpenWebText](https://huggingface.co/datasets/openwebtext) are some of the more commonly used training sets, and the skewing of language is rife within them.

To use Common Crawl as an example, a study by Wang et al. (2021) found that English made up a huge 63.9% majority, with the next largest language inclusion being Chinese at 8.9%. The third, fourth, and fifth place getters for this set were German, Spanish, and French at 4.7%, 4.6%, and 4.2% respectively. And these figures or reflected across all of these training sets. According to a recent study, only 15% of the world's languages have a Wikipedia page, and only 4% have more than 100,000 articles, meaning that most of the world’s languages are either severely underrepresented, or not represented at all.

This imbalance in data availability and quality has serious implications for the performance and fairness of LLMs and other related generative data models. They tend to perform better on languages and topics that are well-represented in their training data, and worse on those that are not. This creates a feedback loop that reinforces the dominance of major languages and marginalizes minor languages. What this feedback loop also implies is the assertion that everybody that wishes to use these AI models and tools will speak and understand English, as well as solidifying English as being seen as the “global” language.

One has only to draw an analogy with colonialism and colonization to have a historical reference point for the potential negative impacts this lack of inclusivity could cause. Colonization was a process of political and economic domination that resulted in the suppression and eradication of many local cultures and languages around the world and, similarly, LLMs may exert a form of linguistic imperialism that threatens the survival and vitality of minor languages. By privileging certain languages over others, LLMs may contribute to language shift, language loss, and language death. This would be a great loss for humanity, as languages are not only means of communication, but also repositories of cultural heritage, identity, and knowledge.

Moreover, just as Latin now exists largely as a written only language, there are also languages that are almost impossible to represent in this training data as they have no written or phonetic alphabet as they are only spoken. These languages cannot then be easily trained into our AI overlords and so are naturally doomed to be excluded and forgotten.

With the metaphorical (and literal) “AI arms race” well and truly underway, however, it’s easy to see how concerns about the inclusiveness of languages within the models are going to fall largely by the wayside. We’ve seen historically that the arbitrary North Star of progress shines bright to the exclusion of all else. But as a human being and a lover of language it doesn’t ring true to throw away the lessons learned from centuries past and to once again watch English take over the world and marginalize the same people that have already been through enough.
